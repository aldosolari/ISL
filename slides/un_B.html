<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aldo Solari">

<title>The Bias-Variance Trade-off</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="un_B_files/libs/clipboard/clipboard.min.js"></script>
<script src="un_B_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="un_B_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="un_B_files/libs/quarto-html/popper.min.js"></script>
<script src="un_B_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="un_B_files/libs/quarto-html/anchor.min.js"></script>
<link href="un_B_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="un_B_files/libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="un_B_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="un_B_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="un_B_files/libs/bootstrap/bootstrap-721140556699abb0ff907dddd6c78b98.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#yesterdays-and-tomorrows-data" id="toc-yesterdays-and-tomorrows-data" class="nav-link active" data-scroll-target="#yesterdays-and-tomorrows-data">Yesterday’s and tomorrow’s data</a>
  <ul class="collapse">
  <li><a href="#the-signal-and-the-noise" id="toc-the-signal-and-the-noise" class="nav-link" data-scroll-target="#the-signal-and-the-noise">The signal and the noise</a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  <li><a href="#yesterdays-data" id="toc-yesterdays-data" class="nav-link" data-scroll-target="#yesterdays-data">Yesterday’s data</a></li>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression" class="nav-link" data-scroll-target="#simple-linear-regression">Simple linear regression</a></li>
  <li><a href="#estimation-of-the-parameters-by-least-squares" id="toc-estimation-of-the-parameters-by-least-squares" class="nav-link" data-scroll-target="#estimation-of-the-parameters-by-least-squares">Estimation of the parameters by least squares</a></li>
  <li><a href="#least-squares-fit-hat-y-0.520627---0.003-x" id="toc-least-squares-fit-hat-y-0.520627---0.003-x" class="nav-link" data-scroll-target="#least-squares-fit-hat-y-0.520627---0.003-x">Least squares fit : <span class="math inline">\hat y = 0.520627 - 0.003 x</span></a></li>
  <li><a href="#assessing-the-overall-accuracy-of-the-model" id="toc-assessing-the-overall-accuracy-of-the-model" class="nav-link" data-scroll-target="#assessing-the-overall-accuracy-of-the-model">Assessing the Overall Accuracy of the Model</a></li>
  <li><a href="#section-1" id="toc-section-1" class="nav-link" data-scroll-target="#section-1"></a></li>
  <li><a href="#polynomial-regression" id="toc-polynomial-regression" class="nav-link" data-scroll-target="#polynomial-regression">Polynomial regression</a></li>
  <li><a href="#estimating-polynomial-regression" id="toc-estimating-polynomial-regression" class="nav-link" data-scroll-target="#estimating-polynomial-regression">Estimating Polynomial Regression</a></li>
  <li><a href="#solution" id="toc-solution" class="nav-link" data-scroll-target="#solution">Solution</a></li>
  <li><a href="#matrix-multiplication" id="toc-matrix-multiplication" class="nav-link" data-scroll-target="#matrix-multiplication">Matrix Multiplication</a></li>
  <li><a href="#matrix-inverse" id="toc-matrix-inverse" class="nav-link" data-scroll-target="#matrix-inverse">Matrix Inverse</a></li>
  <li><a href="#yesterdays-data-polynomial-regression" id="toc-yesterdays-data-polynomial-regression" class="nav-link" data-scroll-target="#yesterdays-data-polynomial-regression">Yesterday’s data, polynomial regression</a></li>
  <li><a href="#yesterdays-data-goodness-of-fit" id="toc-yesterdays-data-goodness-of-fit" class="nav-link" data-scroll-target="#yesterdays-data-goodness-of-fit">Yesterday’s data, goodness of fit</a></li>
  <li><a href="#yesterdays-data-polynomial-interpolation-p-n" id="toc-yesterdays-data-polynomial-interpolation-p-n" class="nav-link" data-scroll-target="#yesterdays-data-polynomial-interpolation-p-n">Yesterday’s data, polynomial interpolation (<span class="math inline">d = n-1</span>)</a></li>
  <li><a href="#yesterdays-data-tomorrows-prediction" id="toc-yesterdays-data-tomorrows-prediction" class="nav-link" data-scroll-target="#yesterdays-data-tomorrows-prediction">Yesterday’s data, tomorrow’s prediction</a></li>
  <li><a href="#tomorrows-data-polynomial-regression" id="toc-tomorrows-data-polynomial-regression" class="nav-link" data-scroll-target="#tomorrows-data-polynomial-regression">Tomorrow’s data, polynomial regression</a></li>
  <li><a href="#tomorrows-data-goodness-of-fit" id="toc-tomorrows-data-goodness-of-fit" class="nav-link" data-scroll-target="#tomorrows-data-goodness-of-fit">Tomorrow’s data, goodness of fit</a></li>
  <li><a href="#mse-on-training-and-test-set" id="toc-mse-on-training-and-test-set" class="nav-link" data-scroll-target="#mse-on-training-and-test-set">MSE on training and test set</a></li>
  <li><a href="#comments-and-remarks" id="toc-comments-and-remarks" class="nav-link" data-scroll-target="#comments-and-remarks">Comments and remarks</a></li>
  </ul></li>
  <li><a href="#the-bias-variance-trade-off" id="toc-the-bias-variance-trade-off" class="nav-link" data-scroll-target="#the-bias-variance-trade-off">The Bias-Variance Trade-Off</a>
  <ul class="collapse">
  <li><a href="#prediction-error" id="toc-prediction-error" class="nav-link" data-scroll-target="#prediction-error">Prediction error</a></li>
  <li><a href="#sources-of-error" id="toc-sources-of-error" class="nav-link" data-scroll-target="#sources-of-error">Sources of Error</a></li>
  <li><a href="#reducible-and-irreducible-error" id="toc-reducible-and-irreducible-error" class="nav-link" data-scroll-target="#reducible-and-irreducible-error">Reducible and Irreducible Error</a></li>
  <li><a href="#reducible-error-the-bias-variance-tradeoff" id="toc-reducible-error-the-bias-variance-tradeoff" class="nav-link" data-scroll-target="#reducible-error-the-bias-variance-tradeoff">Reducible error: the bias-variance tradeoff</a></li>
  <li><a href="#low-flexibility-high-bias-low-variance" id="toc-low-flexibility-high-bias-low-variance" class="nav-link" data-scroll-target="#low-flexibility-high-bias-low-variance">Low flexibility: high bias, low variance</a></li>
  <li><a href="#high-flexibility-low-bias-high-variance" id="toc-high-flexibility-low-bias-high-variance" class="nav-link" data-scroll-target="#high-flexibility-low-bias-high-variance">High flexibility: low bias, high variance</a></li>
  <li><a href="#optimal-choice" id="toc-optimal-choice" class="nav-link" data-scroll-target="#optimal-choice">Optimal choice</a></li>
  <li><a href="#bias-variance-as-a-function-of-flexibility" id="toc-bias-variance-as-a-function-of-flexibility" class="nav-link" data-scroll-target="#bias-variance-as-a-function-of-flexibility">Bias-Variance as a function of flexibility</a></li>
  <li><a href="#comments-and-remarks-1" id="toc-comments-and-remarks-1" class="nav-link" data-scroll-target="#comments-and-remarks-1">Comments and remarks</a></li>
  </ul></li>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation">Cross-validation</a>
  <ul class="collapse">
  <li><a href="#training-error-versus-test-error" id="toc-training-error-versus-test-error" class="nav-link" data-scroll-target="#training-error-versus-test-error">Training Error versus Test error</a></li>
  <li><a href="#training--versus-test-set-performance" id="toc-training--versus-test-set-performance" class="nav-link" data-scroll-target="#training--versus-test-set-performance">Training- versus Test-Set Performance</a></li>
  <li><a href="#validation-set-approach" id="toc-validation-set-approach" class="nav-link" data-scroll-target="#validation-set-approach">Validation-set approach</a></li>
  <li><a href="#the-validation-process" id="toc-the-validation-process" class="nav-link" data-scroll-target="#the-validation-process">The Validation process</a></li>
  <li><a href="#example-yesterday-tomorrow-data" id="toc-example-yesterday-tomorrow-data" class="nav-link" data-scroll-target="#example-yesterday-tomorrow-data">Example: yesterday-tomorrow data</a></li>
  <li><a href="#drawbacks-of-validation-set-approach" id="toc-drawbacks-of-validation-set-approach" class="nav-link" data-scroll-target="#drawbacks-of-validation-set-approach">Drawbacks of validation set approach</a></li>
  <li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation">K-fold Cross-validation</a></li>
  <li><a href="#k-fold-cross-validation-in-detail" id="toc-k-fold-cross-validation-in-detail" class="nav-link" data-scroll-target="#k-fold-cross-validation-in-detail"><span class="math inline">K</span>-fold Cross-validation in detail</a></li>
  <li><a href="#the-details" id="toc-the-details" class="nav-link" data-scroll-target="#the-details">The details</a></li>
  <li><a href="#leave-one-out-cross-validation" id="toc-leave-one-out-cross-validation" class="nav-link" data-scroll-target="#leave-one-out-cross-validation">Leave-One-Out Cross-Validation</a></li>
  <li><a href="#example-yesterday-tomorrow-data-1" id="toc-example-yesterday-tomorrow-data-1" class="nav-link" data-scroll-target="#example-yesterday-tomorrow-data-1">Example: yesterday-tomorrow data</a></li>
  <li><a href="#on-the-choice-of-k" id="toc-on-the-choice-of-k" class="nav-link" data-scroll-target="#on-the-choice-of-k">On the Choice of <span class="math inline">K</span></a></li>
  <li><a href="#required-readings-from-the-textbook-and-course-materials" id="toc-required-readings-from-the-textbook-and-course-materials" class="nav-link" data-scroll-target="#required-readings-from-the-textbook-and-course-materials">Required readings from the textbook and course materials</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="un_B_slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
</div>
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Bias-Variance Trade-off</h1>
<p class="subtitle lead">Introduction to Statistical Learning - PISE</p>
</div>


<div class="quarto-title-meta-author column-page-left">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><span class="orange">Aldo Solari</span> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <em>Ca’ Foscari University of Venice</em>
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-page-left">

      
  
    
  </div>
  


</header>


<p>This unit will cover the following <span class="orange">topics</span>:</p>
<ul>
<li>Simple linear regression</li>
<li>Polynomial regression</li>
<li>Bias-variance trade-off</li>
<li>Cross-validation</li>
</ul>
<section id="yesterdays-and-tomorrows-data" class="level1">
<h1>Yesterday’s and tomorrow’s data</h1>
<section id="the-signal-and-the-noise" class="level2">
<h2 class="anchored" data-anchor-id="the-signal-and-the-noise">The signal and the noise</h2>
<ul>
<li><p>Let us presume that <span class="orange">yesterday</span> we observed <span class="math inline">n = 30</span> pairs of data <span class="math inline">(x_i, y_i)</span>.</p></li>
<li><p>Data were generated according to <span class="math display">
  Y_i = f(x_i) + \epsilon_i, \quad i=1,\dots,n,
  </span> with each <span class="math inline">y_i</span> being the realization of <span class="math inline">Y_i</span>.</p></li>
<li><p>The <span class="math inline">\epsilon_1,\dots,\epsilon_n</span> are iid “<span class="orange">error</span>” terms, such that <span class="math inline">\mathbb{E}(\epsilon_i)=0</span> and <span class="math inline">\mathbb{V}\text{ar}(\epsilon_i)=\sigma^2 = 10^{-4}</span>.</p></li>
<li><p>Here <span class="math inline">f(x)</span> is a regression function (<span class="blue">signal</span>) that we leave unspecified .</p></li>
<li><p><span class="blue">Tomorrow</span> we will get a new <span class="math inline">x</span>. We wish to <span class="orange">predict</span> <span class="math inline">Y</span>.</p></li>
</ul>
</section>
<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section"></h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="yesterdays-data" class="level2">
<h2 class="anchored" data-anchor-id="yesterdays-data">Yesterday’s data</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
<!-- ## Overfitting: mistaking noise for the signal -->
<!-- ```{r} -->
<!-- #| fig-width: 5 -->
<!-- #| fig-height: 4.5 -->
<!-- #| fig-align: center -->
<!-- #| warning: false -->
<!-- degree = 15 -->
<!-- fit <- lm(y.yesterday ~ poly(x, degree = degree, raw = FALSE), data = dataset) -->
<!-- # Fitted values -->
<!-- x_seq <- seq(from = min(dataset$x), to = max(dataset$x), length = 30000)  -->
<!-- y_hat <- predict(fit, newdata = data.frame(x = x_seq)) -->
<!-- data_pred <- data.frame(x = x_seq, y_hat = y_hat) -->
<!-- ggplot(data = dataset, aes(x = x, y = y.yesterday)) + -->
<!--   geom_line(data = dataset, aes(x = x, y = ftrue), col="blue") + -->
<!--   geom_line(data = data_pred, aes(x = x_seq, y = y_hat)) + -->
<!--   geom_point() + -->
<!--   theme_light() + -->
<!--   scale_color_tableau(palette = "Color Blind") + -->
<!--   xlab("x") + -->
<!--   ylab("y") -->
<!-- ``` -->
</section>
<section id="simple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="simple-linear-regression">Simple linear regression</h2>
<div class="incremental">
<ul class="incremental">
<li><p>The function <span class="math inline">f(x)</span> is unknown, therefore, it should be estimated.</p></li>
<li><p>A simple approach is using <span class="blue">simple linear regression</span>: <span class="math display">
f(x; \beta) = \beta_0 + \beta_1 x,
</span> namely <span class="math inline">f(x)</span> is <span class="orange">approximated</span> with a straight line where <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span> are two unknown constants that represent the <span class="blue">intercept</span> and <span class="blue">slope</span>, also known as <span class="orange">coefficients</span> or <span class="orange">parameters</span></p></li>
<li><p>Giving some <span class="orange">estimates</span> <span class="math inline">\hat{\beta}_0</span> and <span class="math inline">\hat{\beta}_1</span> for the model coefficients, we predict future values using <span class="math display">\hat{y} =  \hat\beta_0 + \hat\beta_1 x</span> where <span class="math inline">\hat{y}</span> indicates a <span class="blue">prediction</span> of <span class="math inline">Y</span> on the basis of <span class="math inline">X=x</span>. The <span class="orange">hat</span> symbol denotes an estimated value.</p></li>
</ul>
</div>
</section>
<section id="estimation-of-the-parameters-by-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="estimation-of-the-parameters-by-least-squares">Estimation of the parameters by least squares</h2>
<div class="incremental">
<ul class="incremental">
<li><p>Let <span class="math inline">\hat y_i = \hat\beta_0 + \hat\beta_1 x_i</span> be the prediction for <span class="math inline">Y</span> based on the <span class="math inline">i</span>th value of <span class="math inline">X</span>. Then <span class="math inline">e_i = y_i - \hat y_i</span> represents the <span class="math inline">i</span>th <span class="blue">residual</span></p></li>
<li><p>We define the <span class="blue">residual sum of squares</span> (<span class="math inline">\mathrm{RSS}</span>) as <span class="math display">\mathrm{RSS} = e_1^2+e_2^2+\ldots+e_n^2,</span> or equivalently as <span class="math display">\mathrm{RSS} = (y_1 - \hat\beta_0 - \hat\beta_1 x_1)^2+(y_2 - \hat\beta_0 -
\hat\beta_1 x_2)^2+\ldots+ (y_n- \hat\beta_0 - \hat\beta_1 x_n)^2.</span></p></li>
<li><p>The <span class="blue">least squares</span> approach chooses <span class="math inline">\hat{\beta}_0</span> and <span class="math inline">\hat{\beta}_1</span> to minimize the . The minimizing values can be shown to be <span class="math display">
\begin{aligned}
\hat{\beta}_1 &amp;= \frac{\sum_{i=1}^{n}(x_i - \bar x)(y_i - \bar y)}{\sum_{i=1}^{n}(x_i - \bar x)^2}\\
\hat{\beta}_0 &amp;= \bar y - \beta_1 \bar x
\end{aligned}
</span> where <span class="math inline">\bar y = \frac{1}{n}\sum_{i=1}^n y_i</span> and <span class="math inline">\bar x = \frac{1}{n}\sum_{i=1}^n x_i</span> are the sample means.</p></li>
</ul>
</div>
</section>
<section id="least-squares-fit-hat-y-0.520627---0.003-x" class="level2">
<h2 class="anchored" data-anchor-id="least-squares-fit-hat-y-0.520627---0.003-x">Least squares fit : <span class="math inline">\hat y = 0.520627 - 0.003 x</span></h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="assessing-the-overall-accuracy-of-the-model" class="level2">
<h2 class="anchored" data-anchor-id="assessing-the-overall-accuracy-of-the-model">Assessing the Overall Accuracy of the Model</h2>
<div class="incremental">
<ul class="incremental">
<li><p>We compute the <span class="blue">mean squared error</span> (<span class="math inline">\mathrm{MSE}</span>) <span class="math display">\mathrm{MSE} = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2  = \frac{1}{n}\mathrm{RSS}</span></p></li>
<li><p><span class="blue">R-squared</span> or fraction of variance explained is <span class="math display">R^2 = \frac{\mathrm{TSS} - \mathrm{RSS}}{\mathrm{TSS}} = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}}</span> where <span class="math inline">\mathrm{TSS} = \sum_{i=1}^{n}(y_i - \bar y)^2</span> is the <span class="blue">total sum of squares</span>.</p></li>
</ul>
</div>
</section>
<section id="section-1" class="level2">
<h2 class="anchored" data-anchor-id="section-1"></h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Quantity</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RSS</td>
<td>0.0171726</td>
</tr>
<tr class="even">
<td>MSE</td>
<td>0.00057242</td>
</tr>
<tr class="odd">
<td>TSS</td>
<td>0.01731363</td>
</tr>
<tr class="even">
<td><span class="math inline">R^2</span></td>
<td>0.008146</td>
</tr>
</tbody>
</table>
</section>
<section id="polynomial-regression" class="level2">
<h2 class="anchored" data-anchor-id="polynomial-regression">Polynomial regression</h2>
<div class="incremental">
<ul class="incremental">
<li><p>The function <span class="math inline">f(x)</span> is unknown, therefore, it should be estimated.</p></li>
<li><p>A simple approach is using <span class="orange">polynomial regression</span>: <span class="math display">
f(x; \beta) = \beta_0 + \beta_1 x + \beta_2 x^2 + \cdots + \beta_d x^{d},
</span> namely <span class="math inline">f(x)</span> is <span class="orange">approximated</span> with a polynomial of degree <span class="math inline">d</span></p></li>
<li><p>This model is linear in the parameters: ordinary least squares can be applied.</p></li>
<li><p>How do we choose the <span class="blue">degree of the polynomial</span> <span class="math inline">d</span>?</p></li>
<li><p>Without clear guidance, in principle, any value of <span class="math inline">d \in \{0,\dots,n-1\}</span> could be appropriate.</p></li>
<li><p>Let us compare the <span class="blue">mean squared error</span> (MSE) on yesterday’s data (<span class="orange">training</span>) <span class="math display">
\text{MSE}_{\text{train}} = \frac{1}{n}\sum_{i=1}^n\{y_i -f(x_i; \hat{\beta})\}^2,
</span> or alternatively <span class="math inline">R^2_\text{train}</span>, for different values of <span class="math inline">d</span>…</p></li>
</ul>
</div>
</section>
<section id="estimating-polynomial-regression" class="level2">
<h2 class="anchored" data-anchor-id="estimating-polynomial-regression">Estimating Polynomial Regression</h2>
<p>Let</p>
<p><span class="math display">
\mathbf{y} = (y_1,\dots,y_n)^\top
</span></p>
<p>be the vector of observed responses, and let <span class="math inline">\mathbf{X} \in \mathbb{R}^{n \times (d+1)}</span> be the design matrix whose <span class="math inline">i</span>-th row is</p>
<p><span class="math display">
(1, x_i, x_i^2, \dots, x_i^d).
</span></p>
<p><span class="orange">Ordinary least squares</span> (OLS) estimation chooses the coefficient vector</p>
<p><span class="math display">
\hat{\beta}
=
\begin{pmatrix}
\hat{\beta}_0 \\
\hat{\beta}_1 \\
\vdots \\
\hat{\beta}_d
\end{pmatrix}
\in \mathbb{R}^{d+1}
</span></p>
<p>to <strong>minimize the residual sum of squares (RSS)</strong>:</p>
<p><span class="math display">
\hat{\beta}
=
\arg\min_{\beta \in \mathbb{R}^{d+1}}
\sum_{i=1}^n
\bigl(y_i - f(x_i; \beta)\bigr)^2.
</span> Thus, OLS finds the coefficients that make the fitted polynomial as close as possible (in squared distance) to the observed data.</p>
</section>
<section id="solution" class="level2">
<h2 class="anchored" data-anchor-id="solution">Solution</h2>
<p>The solution to this optimization problem is</p>
<p><span class="math display">
\hat{\beta}
=
(\mathbf{X}^\top \mathbf{X})^{-1}
\mathbf{X}^\top \mathbf{y},
</span></p>
<p>We avoid matrix algebra whenever possible, but in the OLS formula it is useful to understand matrix multiplication and inversion.</p>
</section>
<section id="matrix-multiplication" class="level2">
<h2 class="anchored" data-anchor-id="matrix-multiplication">Matrix Multiplication</h2>
<p>Suppose</p>
<p><span class="math display">
\mathbf{A} \in \mathbb{R}^{r \times d},
\quad
\mathbf{B} \in \mathbb{R}^{d \times s}.
</span></p>
<p>Then the product <span class="math inline">\mathbf{A}\mathbf{B}</span> is an <span class="math inline">r \times s</span> matrix defined only if the number of columns of <span class="math inline">\mathbf{A}</span> equals the number of rows of <span class="math inline">\mathbf{B}</span>.</p>
<p>The <span class="math inline">(i,j)</span>-th element of <span class="math inline">\mathbf{A}\mathbf{B}</span> is</p>
<p><span class="math display">
(\mathbf{A}\mathbf{B})_{ij}
=
\sum_{k=1}^{d} a_{ik} b_{kj}.
</span></p>
<p>That is:</p>
<ul>
<li>Take the <span class="math inline">i</span>-th row of <span class="math inline">\mathbf{A}</span>,</li>
<li>Take the <span class="math inline">j</span>-th column of <span class="math inline">\mathbf{B}</span>,</li>
<li>Multiply corresponding elements,</li>
<li>Sum the results.</li>
</ul>
</section>
<section id="matrix-inverse" class="level2">
<h2 class="anchored" data-anchor-id="matrix-inverse">Matrix Inverse</h2>
<p>A square matrix <span class="math inline">\mathbf{A} \in \mathbb{R}^{p \times p}</span> has an inverse <span class="math inline">\mathbf{A}^{-1}</span> if</p>
<p><span class="math display">
\mathbf{A}\mathbf{A}^{-1}
=
\mathbf{A}^{-1}\mathbf{A}
=
\mathbf{I}_p,
</span></p>
<p>where <span class="math inline">\mathbf{I}_p</span> is the <span class="math inline">p \times p</span> identity matrix.</p>
<p>The inverse exists only if:</p>
<ul>
<li><span class="math inline">\mathbf{A}</span> is square,</li>
<li><span class="math inline">\mathbf{A}</span> is nonsingular (its columns are linearly independent).</li>
</ul>
</section>
<section id="yesterdays-data-polynomial-regression" class="level2">
<h2 class="anchored" data-anchor-id="yesterdays-data-polynomial-regression">Yesterday’s data, polynomial regression</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1170"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="yesterdays-data-goodness-of-fit" class="level2">
<h2 class="anchored" data-anchor-id="yesterdays-data-goodness-of-fit">Yesterday’s data, goodness of fit</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="yesterdays-data-polynomial-interpolation-p-n" class="level2">
<h2 class="anchored" data-anchor-id="yesterdays-data-polynomial-interpolation-p-n">Yesterday’s data, polynomial interpolation (<span class="math inline">d = n-1</span>)</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1350"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="yesterdays-data-tomorrows-prediction" class="level2">
<h2 class="anchored" data-anchor-id="yesterdays-data-tomorrows-prediction">Yesterday’s data, tomorrow’s prediction</h2>
<div class="incremental">
<ul class="incremental">
<li><p>The <span class="blue">MSE</span> decreases as the number of parameter increases; similarly, the <span class="blue"><span class="math inline">R^2</span></span> increases as a function of <span class="math inline">d</span>. It can be <span class="orange">proved</span> that this <span class="orange">always happens</span> using ordinary least squares.</p></li>
<li><p>One might be tempted to let <span class="math inline">d</span> as large as possible to make the model more flexible…</p></li>
<li><p>Taking this reasoning to the extreme would lead to the choice <span class="math inline">d = n-1</span>, so that <span class="math display">
\text{MSE}_\text{train} = 0, \qquad R^2_\text{train} = 1,
</span> i.e., a perfect fit. This procedure is called <span class="blue">interpolation</span>.</p></li>
<li><p>However, we are <span class="orange">not</span> interested in predicting <span class="orange">yesterday</span> data. Our goal is to predict <span class="blue">tomorrow</span>’s data, i.e.&nbsp;a <span class="blue">new set</span> of <span class="math inline">n = 30</span> points: <span class="math display">
(x_1, \tilde{y}_1), \dots, (x_n, \tilde{y}_n),
</span> using <span class="math inline">\hat{y}_i = f(x_i; \hat{\beta})</span>, where <span class="math inline">\hat{\beta}</span> is obtained using yesterday’s data.</p></li>
<li><p><span class="orange">Remark</span>. Tomorrow’s r.v. <span class="math inline">\tilde{Y}_1,\dots, \tilde{Y}_n</span> follow the same scheme as yesterday’s data.</p></li>
</ul>
</div>
</section>
<section id="tomorrows-data-polynomial-regression" class="level2">
<h2 class="anchored" data-anchor-id="tomorrows-data-polynomial-regression">Tomorrow’s data, polynomial regression</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1200"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="tomorrows-data-goodness-of-fit" class="level2">
<h2 class="anchored" data-anchor-id="tomorrows-data-goodness-of-fit">Tomorrow’s data, goodness of fit</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="750"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="mse-on-training-and-test-set" class="level2">
<h2 class="anchored" data-anchor-id="mse-on-training-and-test-set">MSE on training and test set</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1200"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comments-and-remarks" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-remarks">Comments and remarks</h2>
<div class="incremental">
<ul class="incremental">
<li><p>The mean squared error on tomorrow’s data (<span class="blue">test</span>) is defined as <span class="math display">
\text{MSE}_{\text{test}} = \frac{1}{n}\sum_{i=1}^n\{\tilde{y}_i -f(x_i; \hat{\beta})\}^2,
</span> and similarly the <span class="math inline">R^2_\text{test}</span>. We would like the <span class="math inline">\text{MSE}_{\text{test}}</span> to be <span class="orange">as small as possible</span>.</p></li>
<li><p>For <span class="blue">small values</span> of <span class="math inline">d</span>, an increase in the degree of the polynomial <span class="blue">improves the fit</span>. In other words, at the beginning, both the <span class="math inline">\text{MSE}_{\text{train}}</span> and the <span class="math inline">\text{MSE}_{\text{test}}</span> decrease.</p></li>
<li><p>For <span class="orange">larger values</span> of <span class="math inline">d</span>, the improvement gradually ceases, and the polynomial follows <span class="orange">random fluctuations</span> in yesterday’s data, which are <span class="blue">not observed</span> in the <span class="blue">new sample</span>.</p></li>
<li><p>An over-adaptation to yesterday’s data is called <span class="orange">overfitting</span>, which occurs when the training <span class="math inline">\text{MSE}_{\text{train}}</span> is low but the test <span class="math inline">\text{MSE}_{\text{test}}</span> is high.</p></li>
<li><p>Yesterday’s dataset is available from the website of the textbook Azzalini and Scarpa. (2013):</p>
<ul class="incremental">
<li>Dataset <a href="http://azzalini.stat.unipd.it/Book-DM/yesterday.dat" class="uri">http://azzalini.stat.unipd.it/Book-DM/yesterday.dat</a></li>
<li>True <span class="math inline">f(\bm{x})</span> <a href="http://azzalini.stat.unipd.it/Book-DM/f_true.R" class="uri">http://azzalini.stat.unipd.it/Book-DM/f_true.R</a></li>
</ul></li>
</ul>
</div>
</section>
</section>
<section id="the-bias-variance-trade-off" class="level1">
<h1>The Bias-Variance Trade-Off</h1>
<section id="prediction-error" class="level2">
<h2 class="anchored" data-anchor-id="prediction-error">Prediction error</h2>
<p>Suppose we predict <span class="math inline">\tilde Y_i</span> by <span class="math inline">\hat{f}(x_i)</span> where <span class="math inline">\hat f</span> is estimated from the training data.</p>
<p>Our goal is to minimize the (expected) prediction error <span class="math display">\mathbb{E}[\text{MSE}_{\text{test}}] = \frac{1}{n}\sum_{i=1}^n\mathbb{E}\Big[ (\tilde{Y}_i -\hat f(x_i) )^2 \Big],</span> where the response variable is given by a signal-plus-noise model, <span class="math display">Y = f(x) + \varepsilon,</span> with <span class="math inline">f(x)</span> representing the true underlying signal and <span class="math inline">\varepsilon</span> the random error term</p>
</section>
<section id="sources-of-error" class="level2">
<h2 class="anchored" data-anchor-id="sources-of-error">Sources of Error</h2>
<ul>
<li><p><strong>Irreducible Error</strong> Can we make predictions without committing errors? No — not even if we knew the true function <span class="math inline">f</span>, because of the presence of the error term <span class="math inline">\varepsilon</span></p></li>
<li><p><strong>Bias</strong> How far (on average) is the estimator <span class="math inline">\hat f</span> from the true function <span class="math inline">f</span>? For example, if we estimate a linear regression line when the true relationship is quadratic.</p></li>
<li><p><strong>Variance</strong> How variable is the estimator <span class="math inline">\hat f</span>? In other words, how much would our estimates change if we computed them using different training sets?</p></li>
</ul>
</section>
<section id="reducible-and-irreducible-error" class="level2">
<h2 class="anchored" data-anchor-id="reducible-and-irreducible-error">Reducible and Irreducible Error</h2>
<p><span class="math display">
\mathbb{E}\big[(\tilde Y_i - \hat{f}(x_i))^2\big]
=
\mathbb{E}\big[(f(x_i) + \tilde \varepsilon_i - \hat{f}(x_i))^2\big].
</span></p>
<p>Expanding and using <span class="math inline">\mathbb{E}[\tilde \varepsilon_i] = 0</span>,</p>
<p><span class="math display">
=
\underbrace{\mathbb{E}\big[(f(x_i) - \hat{f}(x_i))^2\big]}_{\text{Reducible error}}
+
\underbrace{\mathrm{Var}(\tilde \varepsilon_i)}_{\text{Irreducible error}}.
</span></p>
<p>The <span class="orange">prediction error</span> is the sum of a <span class="blue">reducible</span> and an <span class="blue">irreducible</span> component.</p>
</section>
<section id="reducible-error-the-bias-variance-tradeoff" class="level2">
<h2 class="anchored" data-anchor-id="reducible-error-the-bias-variance-tradeoff">Reducible error: the bias-variance tradeoff</h2>
<p>The reducible error can be further decomposed into the <span class="blue">squared bias</span> and the <span class="blue">variance</span> of the estimator <span class="math inline">\hat{f}</span>.</p>
<p><span class="math display">
\begin{aligned}
\mathbb{E}\big[(f(x_i) - \hat{f}(x_i))^2\big]
&amp;= \mathbb{E}\big[(f(x_i) - \mathbb{E}\hat{f}(x_i) + \mathbb{E}\hat{f}(x_i) - \hat{f}(x_i))^2\big] \\
&amp;= \underbrace{\big(f(x_i) - \mathbb{E}\hat{f}(x_i)\big)^2}_{\text{Bias}^2}
+ \underbrace{\mathrm{Var}\big(\hat{f}(x_i)\big)}_{\text{Variance}}.
\end{aligned}
</span></p>
<p>Bias and variance are competing quantities: reducing one typically increases the other.<br>
Hence, we must choose a <span class="orange">trade-off</span> between bias and variance.</p>
<p>Typically as the <span class="blue">flexibility</span> of <span class="math inline">\hat f</span> increases, its variance increases, and its bias decreases.</p>
</section>
<section id="low-flexibility-high-bias-low-variance" class="level2">
<h2 class="anchored" data-anchor-id="low-flexibility-high-bias-low-variance">Low flexibility: high bias, low variance</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="high-flexibility-low-bias-high-variance" class="level2">
<h2 class="anchored" data-anchor-id="high-flexibility-low-bias-high-variance">High flexibility: low bias, high variance</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="optimal-choice" class="level2">
<h2 class="anchored" data-anchor-id="optimal-choice">Optimal choice</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="bias-variance-as-a-function-of-flexibility" class="level2">
<h2 class="anchored" data-anchor-id="bias-variance-as-a-function-of-flexibility">Bias-Variance as a function of flexibility</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comments-and-remarks-1" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-remarks-1">Comments and remarks</h2>
<ul>
<li><p><strong>Reducible error</strong> = <span class="orange">Bias²</span> + <span class="blue">Variance</span></p></li>
<li><p>Models with <span class="orange">low bias</span> tend to have <span class="blue">high variance</span>.</p></li>
<li><p>Models with <span class="blue">low variance</span> tend to have <span class="orange">high bias</span>.</p></li>
<li><p>On one hand, even if our model is <strong>unbiased</strong>,<br>
the prediction error can still be large if the model is highly variable.</p></li>
<li><p>On the other hand, a model that predicts a <strong>constant</strong> has <span class="blue">zero variance</span> but <span class="orange">high bias</span>.</p></li>
<li><p>To achieve good prediction performance, we must <strong>balance</strong> <span class="orange">bias</span> and <span class="blue">variance</span>.</p></li>
</ul>
</section>
</section>
<section id="cross-validation" class="level1">
<h1>Cross-validation</h1>
<section id="training-error-versus-test-error" class="level2">
<h2 class="anchored" data-anchor-id="training-error-versus-test-error">Training Error versus Test error</h2>
<p>Recall the distinction between the <span class="orange">test error</span> and the <span class="blue">training error</span>:</p>
<ul>
<li><p>The <span class="orange">test error</span> is the average error that results from using a statistical learning method to predict the response on a new observation, one that was not used in training the method.</p></li>
<li><p>In contrast, the <span class="blue">training error</span> can be easily calculated by applying the statistical learning method to the observations used in its training.</p></li>
<li><p>But the <span class="blue">training error</span> rate often is quite different from the <span class="orange">test error</span> rate, and in particular the former can dramatically <strong>underestimate</strong> the latter.</p></li>
</ul>
</section>
<section id="training--versus-test-set-performance" class="level2">
<h2 class="anchored" data-anchor-id="training--versus-test-set-performance">Training- versus Test-Set Performance</h2>
<p><img src="img/ELS_2_11.png" class="img-fluid" style="width:100.0%"></p>
<p>Figure from the book <a href="https://hastie.su.domains/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>. Second Edition February 2009. Trevor Hastie, Robert Tibshirani, Jerome Friedman.</p>
</section>
<section id="validation-set-approach" class="level2">
<h2 class="anchored" data-anchor-id="validation-set-approach">Validation-set approach</h2>
<ul>
<li><p>Estimate the test error by <span class="orange">holding out</span> a subset of the training observations from the fitting process</p></li>
<li><p>Here we randomly divide the available set of samples into two parts: a [training set]]{.blue} and a <span class="orange">validation set</span>.</p></li>
<li><p>The model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set.</p></li>
<li><p>The resulting validation-set error provides an estimate of the test error.</p></li>
</ul>
</section>
<section id="the-validation-process" class="level2">
<h2 class="anchored" data-anchor-id="the-validation-process">The Validation process</h2>
<p><img src="img/5_1.png" class="img-fluid" style="width:100.0%"></p>
<p>A random splitting into two halves: left part is training set, right part is validation set</p>
</section>
<section id="example-yesterday-tomorrow-data" class="level2">
<h2 class="anchored" data-anchor-id="example-yesterday-tomorrow-data">Example: yesterday-tomorrow data</h2>
<ul>
<li><p>We randomly split the 30 observations into two sets: a [training set]]{.blue} with 15 data points and a [validation set]]{.orange} with the remaining 15 observations.</p></li>
<li><p>We fit the polynomial regression model on the training set and compute the <strong>MSE</strong> on the validation set.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="drawbacks-of-validation-set-approach" class="level2">
<h2 class="anchored" data-anchor-id="drawbacks-of-validation-set-approach">Drawbacks of validation set approach</h2>
<ul>
<li><p>The validation estimate of the test error can be <span class="orange">highly variable</span>, depending on precisely which observations are included in the training set and which observations are included in the validation set.</p></li>
<li><p>In the validation approach, only a subset of the observations — those that are included in the training set rather than in the validation set — are used to fit the model. This suggests that the validation set error may tend to <span class="blue">overestimate</span> the test error for the model fit on the entire data set.</p></li>
</ul>
</section>
<section id="k-fold-cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="k-fold-cross-validation">K-fold Cross-validation</h2>
<ul>
<li><p>Widely used approach for estimating test error.</p></li>
<li><p>Estimates can be used to select best model, and to give an idea of the test error of the final chosen model.</p></li>
<li><p>Idea is to randomly divide the data into <span class="math inline">K</span> equal-sized parts. We leave out part <span class="math inline">k</span>, fit the model to the other <span class="math inline">K−1</span> parts (combined), and then obtain predictions for the left-out <span class="math inline">k</span>th part.</p></li>
<li><p>This is done in turn for each part <span class="math inline">k= 1,2,...K</span>, and then the results are combined.</p></li>
</ul>
</section>
<section id="k-fold-cross-validation-in-detail" class="level2">
<h2 class="anchored" data-anchor-id="k-fold-cross-validation-in-detail"><span class="math inline">K</span>-fold Cross-validation in detail</h2>
<p>Divide data into <span class="math inline">K</span> roughly equal-sized parts (<span class="math inline">K = 5</span> here)</p>
<p><img src="img/5_5.png" class="img-fluid" style="width:100.0%"></p>
</section>
<section id="the-details" class="level2">
<h2 class="anchored" data-anchor-id="the-details">The details</h2>
<ul>
<li><p>Let the <span class="math inline">K</span> parts (folds) be <span class="math inline">C_1, C_2, \dots, C_K</span>,<br>
where <span class="math inline">C_k</span> denotes the indices of the observations in fold <span class="math inline">k</span>.</p></li>
<li><p>Let <span class="math inline">n_k</span> be the number of observations in fold <span class="math inline">k</span>. Without loss of geenrality, suppose <span class="math inline">n_k = n/K</span>.</p></li>
<li><p>For each fold <span class="math inline">k</span>, fit the model using all data <strong>excluding</strong> <span class="math inline">C_k</span>, and compute the validation mean squared error <span class="math display">
\text{MSE}_k
=
\frac{1}{n_k}
\sum_{i \in C_k}
\bigl(y_i - \hat{y}_i^{-k}\bigr)^2,
</span> where <span class="math inline">\hat{y}_i^{-k}</span> is the prediction for observation <span class="math inline">i</span> obtained from the model trained without fold <span class="math inline">k</span>.</p></li>
<li><p>The <span class="math inline">K</span>-fold cross-validation estimate is their average: <span class="math display">
\text{CV}(K)
=
\frac{1}{K}\sum_{k=1}^{K}
\text{MSE}_k.
</span></p></li>
<li><p>Common choices are <span class="math inline">K=5</span> or <span class="math inline">K=10</span> It is quite evident that a larger <span class="math inline">K</span> requires more computations.</p></li>
</ul>
</section>
<section id="leave-one-out-cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="leave-one-out-cross-validation">Leave-One-Out Cross-Validation</h2>
<ul>
<li>The maximum possible value for <span class="math inline">K</span> is <span class="math inline">n</span>, yielding leave-one-out cross-validation (LOOCV).</li>
</ul>
<p><img src="img/5_3.png" class="img-fluid" style="width:100.0%"></p>
</section>
<section id="example-yesterday-tomorrow-data-1" class="level2">
<h2 class="anchored" data-anchor-id="example-yesterday-tomorrow-data-1">Example: yesterday-tomorrow data</h2>
<ul>
<li><p>The LOOCV is hard to implement because it requires the estimation of <span class="math inline">n</span> different models.</p></li>
<li><p>However, in ordinary least squares there is a brilliant computational shortcut.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_B_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1050"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="on-the-choice-of-k" class="level2">
<h2 class="anchored" data-anchor-id="on-the-choice-of-k">On the Choice of <span class="math inline">K</span></h2>
<ul>
<li><p>A <span class="math inline">K</span>-fold cross-validation with <span class="math inline">K = 5</span> or <span class="math inline">K = 10</span> provides an <strong>upward biased</strong> estimate of the true prediction error <span class="math inline">\mathrm{Err}</span>, because each model is trained on fewer observations than the full dataset (either <span class="math inline">4/5</span> or <span class="math inline">9/10</span> of the data).</p></li>
<li><p>Leave-one-out cross-validation (LOOCV) has <strong>very small bias</strong>, since each model is trained on <span class="math inline">n - 1</span> observations.<br>
However, it has <strong>high variance</strong>, because it averages <span class="math inline">n</span> highly positively correlated error estimates.</p></li>
<li><p>Overall, the choice of <span class="math inline">K</span> is largely <strong>context-dependent</strong>, balancing bias, variance, and computational cost.</p></li>
</ul>
</section>
<section id="required-readings-from-the-textbook-and-course-materials" class="level2">
<h2 class="anchored" data-anchor-id="required-readings-from-the-textbook-and-course-materials">Required readings from the textbook and course materials</h2>
<ul>
<li><strong>Chapter 2: Statistical Learning</strong>
<ul>
<li>2.2 Assessing Model Accuracy</li>
<li>2.2.1 Measuring the Quality of Fit</li>
<li>2.2.2 The Bias-Variance Trade-Off</li>
</ul></li>
<li><strong>Chapter 5: Resampling Methods</strong>
<ul>
<li>5.1 Cross-Validation
<ul>
<li>5.1.1 The Validation Set Approach</li>
<li>5.1.2 Leave-One-Out Cross-Validation</li>
<li>5.1.3 k-Fold Cross-Validation</li>
</ul></li>
</ul></li>
<li><strong>Chapter 7: Moving Beyond Linearity</strong>
<ul>
<li>7.1 Polynomial Regression</li>
</ul></li>
</ul>
<p><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e">Video SL 2.3 Model Selection and Bias Variance Tradeoff - 10:05</a></p>
<p><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e">Video SL 5.1 Cross Validation - 14:02</a></p>
<p><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e">Video SL 5.2 K-fold Cross Validation - 13:34</a></p>
<p><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e">Video SL 7.1 Polynomials and Step Functions - first 7 minutes</a></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="un_B_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>